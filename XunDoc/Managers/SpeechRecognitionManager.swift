//
//  SpeechRecognitionManager.swift
//  XunDoc
//
//  è¯­éŸ³è¯†åˆ«ç®¡ç†å™¨ - å°†å½•éŸ³è½¬ä¸ºæ–‡å­—
//

import Foundation
import Speech
import AVFoundation

class SpeechRecognitionManager: ObservableObject {
    static let shared = SpeechRecognitionManager()
    
    @Published var isTranscribing = false
    @Published var transcriptionProgress: Double = 0
    @Published var transcriptionError: String?
    
    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    
    init() {
        // ä½¿ç”¨ä¸­æ–‡è¯†åˆ«å™¨
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN"))
    }
    
    // MARK: - æƒé™æ£€æŸ¥
    
    func requestAuthorization(completion: @escaping (Bool) -> Void) {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    print("âœ… è¯­éŸ³è¯†åˆ«æƒé™å·²æˆæƒ")
                    completion(true)
                case .denied:
                    print("âŒ ç”¨æˆ·æ‹’ç»äº†è¯­éŸ³è¯†åˆ«æƒé™")
                    completion(false)
                case .restricted:
                    print("âŒ è¯­éŸ³è¯†åˆ«åŠŸèƒ½å—é™")
                    completion(false)
                case .notDetermined:
                    print("âš ï¸ è¯­éŸ³è¯†åˆ«æƒé™æœªç¡®å®š")
                    completion(false)
                @unknown default:
                    completion(false)
                }
            }
        }
    }
    
    // MARK: - éŸ³é¢‘è½¬æ–‡å­—
    
    /// å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºæ–‡å­—
    func transcribeAudio(audioData: Data, completion: @escaping (Result<String, Error>) -> Void) {
        // æ£€æŸ¥æƒé™
        guard SFSpeechRecognizer.authorizationStatus() == .authorized else {
            requestAuthorization { authorized in
                if authorized {
                    self.performTranscription(audioData: audioData, completion: completion)
                } else {
                    completion(.failure(TranscriptionError.notAuthorized))
                }
            }
            return
        }
        
        performTranscription(audioData: audioData, completion: completion)
    }
    
    private func performTranscription(audioData: Data, completion: @escaping (Result<String, Error>) -> Void) {
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            completion(.failure(TranscriptionError.recognizerNotAvailable))
            return
        }
        
        DispatchQueue.main.async {
            self.isTranscribing = true
            self.transcriptionProgress = 0
            self.transcriptionError = nil
        }
        
        // åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(UUID().uuidString + ".m4a")
        
        do {
            try audioData.write(to: tempURL)
            print("ğŸ“ éŸ³é¢‘æ–‡ä»¶å·²å†™å…¥ä¸´æ—¶ç›®å½•: \(tempURL.lastPathComponent)")
        } catch {
            DispatchQueue.main.async {
                self.isTranscribing = false
                completion(.failure(error))
            }
            return
        }
        
        // åˆ›å»ºè¯†åˆ«è¯·æ±‚
        let request = SFSpeechURLRecognitionRequest(url: tempURL)
        request.shouldReportPartialResults = true
        request.taskHint = .dictation
        
        // å¦‚æœæ”¯æŒè®¾å¤‡ä¸Šè¯†åˆ«ï¼ˆéœ€è¦ iOS 13+ï¼‰
        if #available(iOS 13, *) {
            request.requiresOnDeviceRecognition = false // ä½¿ç”¨äº‘ç«¯è¯†åˆ«ä»¥è·å¾—æ›´å¥½çš„å‡†ç¡®åº¦
        }
        
        var finalTranscription = ""
        
        // å¼€å§‹è¯†åˆ«
        recognitionTask = recognizer.recognitionTask(with: request) { [weak self] result, error in
            guard let self = self else { return }
            
            if let result = result {
                finalTranscription = result.bestTranscription.formattedString
                
                DispatchQueue.main.async {
                    // æ ¹æ®æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœæ›´æ–°è¿›åº¦
                    if result.isFinal {
                        self.transcriptionProgress = 1.0
                    } else {
                        // ä¼°ç®—è¿›åº¦ï¼ˆåŸºäºè¯†åˆ«çš„å­—ç¬¦æ•°ï¼‰
                        self.transcriptionProgress = min(0.9, Double(finalTranscription.count) / 200.0)
                    }
                }
                
                print("ğŸ¤ è¯†åˆ«ä¸­: \(finalTranscription)")
                
                // å¦‚æœæ˜¯æœ€ç»ˆç»“æœ
                if result.isFinal {
                    DispatchQueue.main.async {
                        self.isTranscribing = false
                        self.transcriptionProgress = 1.0
                    }
                    
                    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try? FileManager.default.removeItem(at: tempURL)
                    
                    print("âœ… è¯†åˆ«å®Œæˆ: \(finalTranscription)")
                    completion(.success(finalTranscription))
                }
            }
            
            if let error = error {
                DispatchQueue.main.async {
                    self.isTranscribing = false
                    self.transcriptionError = error.localizedDescription
                }
                
                // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try? FileManager.default.removeItem(at: tempURL)
                
                print("âŒ è¯†åˆ«å¤±è´¥: \(error.localizedDescription)")
                completion(.failure(error))
            }
        }
    }
    
    // å–æ¶ˆè¯†åˆ«
    func cancelTranscription() {
        recognitionTask?.cancel()
        recognitionTask = nil
        isTranscribing = false
        transcriptionProgress = 0
    }
    
    // MARK: - æ™ºèƒ½å¯¹è¯åˆ†æ
    
    /// æ™ºèƒ½è¯†åˆ«å¹¶åŒºåˆ†åŒ»ç”Ÿå’Œæ‚£è€…çš„å¯¹è¯
    func transcribeWithSpeakerDetection(audioData: Data, completion: @escaping (Result<[(role: String, text: String)], Error>) -> Void) {
        // å…ˆè¿›è¡Œå®Œæ•´è½¬å½•
        transcribeAudio(audioData: audioData) { [weak self] result in
            guard let self = self else { return }
            
            switch result {
            case .success(let fullText):
                // åˆ†ææ–‡æœ¬,è¯†åˆ«å¯¹è¯è§’è‰²
                let dialogues = self.analyzeDialogueRoles(from: fullText)
                completion(.success(dialogues))
                
            case .failure(let error):
                completion(.failure(error))
            }
        }
    }
    
    /// åˆ†æå¯¹è¯æ–‡æœ¬,è¯†åˆ«åŒ»ç”Ÿå’Œæ‚£è€…
    private func analyzeDialogueRoles(from text: String) -> [(role: String, text: String)] {
        var dialogues: [(role: String, text: String)] = []
        
        // æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²å¯¹è¯
        let sentences = text.components(separatedBy: CharacterSet(charactersIn: "ã€‚ï¼ï¼Ÿ"))
            .map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
            .filter { !$0.isEmpty }
        
        // åŒ»ç”Ÿå¸¸ç”¨è¯æ±‡
        let doctorKeywords = ["åŒ»ç”Ÿ", "å¤§å¤«", "æ£€æŸ¥", "è¯Šæ–­", "å¤„æ–¹", "å»ºè®®", "æ²»ç–—", "è¯ç‰©", "ç—‡çŠ¶",
                            "CT", "Bè¶…", "åŒ–éªŒ", "å¤æŸ¥", "å¼€è¯", "åƒè¯", "ä¼‘æ¯", "æ³¨æ„", "ç¦å¿Œ"]
        
        // æ‚£è€…å¸¸ç”¨è¯æ±‡
        let patientKeywords = ["æˆ‘", "æˆ‘çš„", "ä¸èˆ’æœ", "ç–¼", "ç—›", "éš¾å—", "å¤´æ™•", "å‘çƒ§", "å’³å—½",
                              "è¯·é—®", "åŒ»ç”Ÿ", "æ€ä¹ˆåŠ", "è°¢è°¢", "å¥½çš„", "æ˜ç™½äº†"]
        
        for sentence in sentences {
            // ç»Ÿè®¡å…³é”®è¯å‡ºç°æ¬¡æ•°
            let doctorScore = doctorKeywords.reduce(0) { count, keyword in
                count + (sentence.contains(keyword) ? 1 : 0)
            }
            
            let patientScore = patientKeywords.reduce(0) { count, keyword in
                count + (sentence.contains(keyword) ? 1 : 0)
            }
            
            // åˆ¤æ–­è§’è‰²
            let role: String
            if doctorScore > patientScore {
                role = "åŒ»ç”Ÿ"
            } else if patientScore > doctorScore {
                role = "æ‚£è€…"
            } else {
                // å¦‚æœæ— æ³•åˆ¤æ–­,é»˜è®¤ä¸ºæ‚£è€…(å› ä¸ºæ‚£è€…é€šå¸¸å…ˆè¯´è¯)
                role = dialogues.isEmpty ? "æ‚£è€…" : "åŒ»ç”Ÿ"
            }
            
            dialogues.append((role: role, text: sentence))
        }
        
        return dialogues
    }
    
    // MARK: - é”™è¯¯ç±»å‹
    
    enum TranscriptionError: LocalizedError {
        case notAuthorized
        case recognizerNotAvailable
        case audioFileError
        
        var errorDescription: String? {
            switch self {
            case .notAuthorized:
                return "æœªæˆæƒè¯­éŸ³è¯†åˆ«æƒé™"
            case .recognizerNotAvailable:
                return "è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨"
            case .audioFileError:
                return "éŸ³é¢‘æ–‡ä»¶è¯»å–å¤±è´¥"
            }
        }
    }
}

