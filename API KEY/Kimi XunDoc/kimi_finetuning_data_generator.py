#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kimiå¾®è°ƒæ•°æ®ç”Ÿæˆå™¨
åŸºäºç°æœ‰åŒ»å­¦æ•°æ®ç”Ÿæˆé€‚ç”¨äºæ¨¡å‹å¾®è°ƒçš„é«˜è´¨é‡æ•°æ®é›†
æ”¯æŒå¤šç§æ ¼å¼è½¬æ¢å’ŒQAå¯¹ç”Ÿæˆ
"""

import os
import json
import random
from openai import OpenAI
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime

# APIé…ç½®
API_KEY = "sk-wc9tcOA0q2ShfOjKZ91YStbbyyoMGpiegf6zq54i9kpaQtke"

client = OpenAI(
    api_key=API_KEY,
    base_url="https://api.moonshot.cn/v1",
)

class MedicalDataConverter:
    """åŒ»å­¦æ•°æ®æ ¼å¼è½¬æ¢å™¨"""
    
    def __init__(self, data_dir="/Users/plutoguo/Desktop/All code/API KEY/Kimi XunDoc/jmed_data"):
        self.data_dir = data_dir
        self.output_dir = os.path.join(data_dir, "finetuning_data")
        os.makedirs(self.output_dir, exist_ok=True)
    
    def load_chat_format_data(self, limit=None):
        """åŠ è½½å¯¹è¯æ ¼å¼æ•°æ®"""
        chat_file = os.path.join(self.data_dir, "jmed_chat_format.jsonl")
        data = []
        
        try:
            with open(chat_file, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if limit and i >= limit:
                        break
                    line = line.strip()
                    if line:
                        data.append(json.loads(line))
            print(f"âœ… åŠ è½½äº† {len(data)} æ¡å¯¹è¯æ•°æ®")
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹è¯æ•°æ®å¤±è´¥: {e}")
            return []
    
    def load_eval_data(self, limit=None):
        """åŠ è½½è¯„ä¼°æ•°æ®"""
        eval_file = os.path.join(self.data_dir, "jmed_eval.json")
        try:
            with open(eval_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if limit:
                data = data[:limit]
            print(f"âœ… åŠ è½½äº† {len(data)} æ¡è¯„ä¼°æ•°æ®")
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½è¯„ä¼°æ•°æ®å¤±è´¥: {e}")
            return []
    
    def convert_to_alpaca_format(self, chat_data):
        """è½¬æ¢ä¸ºAlpacaæ ¼å¼"""
        print("ğŸ”„ è½¬æ¢ä¸ºAlpacaæ ¼å¼...")
        alpaca_data = []
        
        for item in chat_data:
            if "messages" in item:
                messages = item["messages"]
                if len(messages) >= 2:
                    user_msg = messages[0]["content"] if messages[0]["role"] == "user" else ""
                    assistant_msg = messages[1]["content"] if messages[1]["role"] == "assistant" else ""
                    
                    # æå–æŒ‡ä»¤å’Œè¾“å…¥
                    if "ä»¥ä¸‹æ˜¯ä¸€é“åŒ»å­¦å¤šé€‰é¢˜" in user_msg:
                        instruction = "è¯·åˆ†æåŒ»å­¦å¤šé€‰é¢˜å¹¶ç»™å‡ºæ­£ç¡®ç­”æ¡ˆå’Œè§£é‡Šã€‚"
                        input_text = user_msg.replace("ä»¥ä¸‹æ˜¯ä¸€é“åŒ»å­¦å¤šé€‰é¢˜ï¼Œè¯·ä»”ç»†åˆ†æåé€‰æ‹©æ­£ç¡®ç­”æ¡ˆï¼š\n\n", "")
                        output_text = assistant_msg
                    else:
                        instruction = "è¯·å›ç­”åŒ»å­¦ç›¸å…³é—®é¢˜ã€‚"
                        input_text = user_msg
                        output_text = assistant_msg
                    
                    alpaca_item = {
                        "instruction": instruction,
                        "input": input_text,
                        "output": output_text
                    }
                    alpaca_data.append(alpaca_item)
        
        print(f"âœ… è½¬æ¢äº† {len(alpaca_data)} æ¡Alpacaæ ¼å¼æ•°æ®")
        return alpaca_data
    
    def convert_to_conversation_format(self, chat_data):
        """è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼"""
        print("ğŸ”„ è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼...")
        conversation_data = []
        
        for item in chat_data:
            if "messages" in item:
                conversation_item = {
                    "messages": item["messages"]
                }
                conversation_data.append(conversation_item)
        
        print(f"âœ… è½¬æ¢äº† {len(conversation_data)} æ¡å¯¹è¯æ ¼å¼æ•°æ®")
        return conversation_data
    
    def save_as_jsonl(self, data, filename):
        """ä¿å­˜ä¸ºJSONLæ ¼å¼"""
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        print(f"ğŸ’¾ ä¿å­˜äº† {len(data)} æ¡æ•°æ®åˆ°: {filepath}")
        return filepath

class QAGenerator:
    """åŸºäºKimi APIçš„QAå¯¹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.generated_qa = []
    
    def generate_qa_from_medical_case(self, case_text, num_questions=3):
        """ä»åŒ»å­¦æ¡ˆä¾‹ç”ŸæˆQAå¯¹"""
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŒ»å­¦æ•™è‚²ä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„åŒ»å­¦æ¡ˆä¾‹ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹ï¼Œç”¨äºåŒ»å­¦æ•™è‚²å’Œæ¨¡å‹è®­ç»ƒã€‚

è¦æ±‚ï¼š
1. ç”Ÿæˆå¤šä¸ªä¸åŒè§’åº¦çš„é—®é¢˜ï¼ˆç—‡çŠ¶åˆ†æã€è¯Šæ–­æ€è·¯ã€é‰´åˆ«è¯Šæ–­ã€æ²»ç–—æ–¹æ¡ˆç­‰ï¼‰
2. æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰è¯¦ç»†ã€å‡†ç¡®çš„ç­”æ¡ˆ
3. é—®é¢˜åº”è¯¥å…·æœ‰æ•™è‚²ä»·å€¼ï¼Œå¸®åŠ©åŒ»å­¦ç”Ÿç†è§£ä¸´åºŠæ€ç»´
4. ç­”æ¡ˆè¦åŒ…å«åŒ»å­¦åŸç†å’Œä¸´åºŠç»éªŒ

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«questionsæ•°ç»„ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å«questionå’Œanswerå­—æ®µã€‚"""

            user_prompt = f"""è¯·åŸºäºä»¥ä¸‹åŒ»å­¦æ¡ˆä¾‹ç”Ÿæˆ {num_questions} ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ï¼š

{case_text}

è¯·ç¡®ä¿é—®é¢˜æ¶µç›–ä¸åŒçš„åŒ»å­¦è§’åº¦ï¼Œç­”æ¡ˆè¯¦ç»†ä¸”å…·æœ‰æ•™è‚²ä»·å€¼ã€‚"""

            completion = client.chat.completions.create(
                model="moonshot-v1-128k",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(completion.choices[0].message.content)
            return result.get("questions", [])
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆQAå¯¹å¤±è´¥: {e}")
            return []
    
    def generate_enhanced_medical_qa(self, original_data, enhancement_types=None):
        """ç”Ÿæˆå¢å¼ºçš„åŒ»å­¦QAå¯¹"""
        if enhancement_types is None:
            enhancement_types = [
                "ç—‡çŠ¶åˆ†æ", "é‰´åˆ«è¯Šæ–­", "æ²»ç–—æ–¹æ¡ˆ", 
                "ç—…ç†æœºåˆ¶", "é¢„åè¯„ä¼°", "é¢„é˜²æªæ–½"
            ]
        
        enhanced_qa = []
        
        for i, item in enumerate(original_data[:10]):  # é™åˆ¶æ•°é‡é¿å…APIè´¹ç”¨è¿‡é«˜
            print(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{min(10, len(original_data))} ä¸ªæ¡ˆä¾‹...")
            
            if "messages" in item:
                user_content = item["messages"][0]["content"]
                
                # æå–åŒ»å­¦æ¡ˆä¾‹æ–‡æœ¬
                if "æ‚£è€…" in user_content:
                    case_start = user_content.find("æ‚£è€…")
                    case_end = user_content.find("æ ¹æ®æ‚£è€…çš„ç—‡çŠ¶")
                    if case_start != -1 and case_end != -1:
                        case_text = user_content[case_start:case_end].strip()
                    else:
                        case_text = user_content[:500]  # å–å‰500å­—ç¬¦
                    
                    # ç”ŸæˆQAå¯¹
                    qa_pairs = self.generate_qa_from_medical_case(case_text, num_questions=3)
                    
                    for qa in qa_pairs:
                        enhanced_item = {
                            "instruction": "è¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚",
                            "input": qa.get("question", ""),
                            "output": qa.get("answer", ""),
                            "source": f"enhanced_case_{i+1}",
                            "category": "medical_education"
                        }
                        enhanced_qa.append(enhanced_item)
        
        print(f"âœ… ç”Ÿæˆäº† {len(enhanced_qa)} æ¡å¢å¼ºQAå¯¹")
        return enhanced_qa
    
    def create_domain_specific_qa(self, domain="åŒ»å­¦è¯Šæ–­"):
        """åˆ›å»ºç‰¹å®šé¢†åŸŸçš„QAå¯¹"""
        try:
            system_prompt = f"""ä½ æ˜¯ä¸€ä½{domain}ä¸“å®¶ã€‚è¯·ç”Ÿæˆä¸€ç³»åˆ—é«˜è´¨é‡çš„é—®ç­”å¯¹ï¼Œç”¨äºè®­ç»ƒä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚

è¦æ±‚ï¼š
1. é—®é¢˜è¦è¦†ç›–{domain}çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹
2. ç­”æ¡ˆè¦å‡†ç¡®ã€è¯¦ç»†ã€å…·æœ‰å®ç”¨ä»·å€¼
3. åŒ…å«ä¸åŒéš¾åº¦çº§åˆ«çš„é—®é¢˜
4. é—®é¢˜è¦å…·æœ‰å®é™…åº”ç”¨ä»·å€¼

è¯·ç”Ÿæˆ10ä¸ªé—®ç­”å¯¹ï¼Œä»¥JSONæ ¼å¼è¿”å›ã€‚"""

            completion = client.chat.completions.create(
                model="moonshot-v1-128k",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·ç”Ÿæˆå…³äº{domain}çš„ä¸“ä¸šé—®ç­”å¯¹"}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(completion.choices[0].message.content)
            questions = result.get("questions", [])
            
            domain_qa = []
            for qa in questions:
                domain_item = {
                    "instruction": f"è¯·å›ç­”å…³äº{domain}çš„é—®é¢˜ã€‚",
                    "input": qa.get("question", ""),
                    "output": qa.get("answer", ""),
                    "source": f"domain_{domain}",
                    "category": domain
                }
                domain_qa.append(domain_item)
            
            print(f"âœ… ç”Ÿæˆäº† {len(domain_qa)} æ¡{domain}ä¸“ä¸šQAå¯¹")
            return domain_qa
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ{domain}QAå¯¹å¤±è´¥: {e}")
            return []

class FineTuningDataPipeline:
    """å¾®è°ƒæ•°æ®å¤„ç†ç®¡é“"""
    
    def __init__(self):
        self.converter = MedicalDataConverter()
        self.qa_generator = QAGenerator()
        self.output_dir = self.converter.output_dir
    
    def create_comprehensive_dataset(self):
        """åˆ›å»ºç»¼åˆå¾®è°ƒæ•°æ®é›†"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹åˆ›å»ºå¾®è°ƒæ•°æ®é›†")
        print("=" * 60)
        
        all_training_data = []
        
        # 1. åŠ è½½å’Œè½¬æ¢ç°æœ‰æ•°æ®
        print("\nğŸ“¥ æ­¥éª¤1: åŠ è½½ç°æœ‰åŒ»å­¦æ•°æ®")
        chat_data = self.converter.load_chat_format_data(limit=100)  # é™åˆ¶æ•°é‡
        
        if chat_data:
            # è½¬æ¢ä¸ºAlpacaæ ¼å¼
            alpaca_data = self.converter.convert_to_alpaca_format(chat_data)
            all_training_data.extend(alpaca_data)
            
            # ä¿å­˜Alpacaæ ¼å¼æ•°æ®
            self.converter.save_as_jsonl(alpaca_data, "medical_alpaca_format.jsonl")
            
            # è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
            conversation_data = self.converter.convert_to_conversation_format(chat_data)
            self.converter.save_as_jsonl(conversation_data, "medical_conversation_format.jsonl")
        
        # 2. ç”Ÿæˆå¢å¼ºQAå¯¹
        print("\nğŸ¯ æ­¥éª¤2: ç”Ÿæˆå¢å¼ºåŒ»å­¦QAå¯¹")
        if chat_data:
            enhanced_qa = self.qa_generator.generate_enhanced_medical_qa(chat_data[:5])  # é™åˆ¶æ•°é‡
            all_training_data.extend(enhanced_qa)
            
            if enhanced_qa:
                self.converter.save_as_jsonl(enhanced_qa, "enhanced_medical_qa.jsonl")
        
        # 3. ç”Ÿæˆé¢†åŸŸä¸“ä¸šQAå¯¹
        print("\nğŸ¥ æ­¥éª¤3: ç”Ÿæˆä¸“ä¸šé¢†åŸŸQAå¯¹")
        domains = ["åŒ»å­¦è¯Šæ–­", "ä¸´åºŠæ²»ç–—", "ç—…ç†åˆ†æ"]
        
        for domain in domains:
            domain_qa = self.qa_generator.create_domain_specific_qa(domain)
            all_training_data.extend(domain_qa)
            
            if domain_qa:
                safe_domain = domain.replace("/", "_")
                self.converter.save_as_jsonl(domain_qa, f"{safe_domain}_qa.jsonl")
        
        # 4. åˆ›å»ºç»¼åˆè®­ç»ƒé›†
        print("\nğŸ“Š æ­¥éª¤4: åˆ›å»ºæœ€ç»ˆè®­ç»ƒæ•°æ®é›†")
        if all_training_data:
            # æ‰“ä¹±æ•°æ®
            random.shuffle(all_training_data)
            
            # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
            split_idx = int(len(all_training_data) * 0.8)
            train_data = all_training_data[:split_idx]
            val_data = all_training_data[split_idx:]
            
            # ä¿å­˜è®­ç»ƒé›†å’ŒéªŒè¯é›†
            train_file = self.converter.save_as_jsonl(train_data, "medical_finetune_train.jsonl")
            val_file = self.converter.save_as_jsonl(val_data, "medical_finetune_val.jsonl")
            
            # ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡
            self.generate_dataset_stats(all_training_data)
            
            print(f"\nâœ… å¾®è°ƒæ•°æ®é›†åˆ›å»ºå®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
            print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_data)} æ¡")
            print(f"ğŸ“Š éªŒè¯é›†: {len(val_data)} æ¡")
            print(f"ğŸ“Š æ€»è®¡: {len(all_training_data)} æ¡")
            
            return train_file, val_file
        
        return None, None
    
    def generate_dataset_stats(self, data):
        """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_samples": len(data),
            "categories": {},
            "sources": {},
            "avg_input_length": 0,
            "avg_output_length": 0,
            "created_at": datetime.now().isoformat()
        }
        
        input_lengths = []
        output_lengths = []
        
        for item in data:
            # ç»Ÿè®¡ç±»åˆ«
            category = item.get("category", "unknown")
            stats["categories"][category] = stats["categories"].get(category, 0) + 1
            
            # ç»Ÿè®¡æ¥æº
            source = item.get("source", "original")
            stats["sources"][source] = stats["sources"].get(source, 0) + 1
            
            # ç»Ÿè®¡é•¿åº¦
            input_len = len(item.get("input", ""))
            output_len = len(item.get("output", ""))
            input_lengths.append(input_len)
            output_lengths.append(output_len)
        
        stats["avg_input_length"] = sum(input_lengths) / len(input_lengths) if input_lengths else 0
        stats["avg_output_length"] = sum(output_lengths) / len(output_lengths) if output_lengths else 0
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(self.output_dir, "dataset_stats.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡å·²ä¿å­˜: {stats_file}")
        return stats

def create_llamafactory_config():
    """åˆ›å»ºLLaMA-Factoryé…ç½®æ–‡ä»¶ç¤ºä¾‹"""
    config = {
        "model_name_or_path": "moonshot-v1-8k",  # å‡è®¾çš„æ¨¡å‹è·¯å¾„
        "finetuning_type": "lora",
        "dataset_dir": "./jmed_data/finetuning_data",
        "dataset": "medical_finetune",
        "cutoff_len": 1024,
        "learning_rate": 5e-5,
        "num_train_epochs": 3,
        "max_samples": 1000,
        "per_device_train_batch_size": 2,
        "gradient_accumulation_steps": 4,
        "lr_scheduler_type": "cosine",
        "max_grad_norm": 1.0,
        "logging_steps": 10,
        "save_steps": 500,
        "warmup_steps": 100,
        "lora_rank": 8,
        "lora_alpha": 32,
        "lora_dropout": 0.1,
        "output_dir": "./saves/medical-kimi-lora",
        "fp16": True,
        "plot_loss": True
    }
    
    config_file = "/Users/plutoguo/Desktop/All code/API KEY/Kimi XunDoc/jmed_data/finetuning_data/llamafactory_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2)
    
    print(f"ğŸ“ LLaMA-Factoryé…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")
    return config_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Kimiå¾®è°ƒæ•°æ®ç”Ÿæˆå™¨")
    print("=" * 40)
    
    try:
        # åˆ›å»ºæ•°æ®å¤„ç†ç®¡é“
        pipeline = FineTuningDataPipeline()
        
        # ç”Ÿæˆç»¼åˆæ•°æ®é›†
        train_file, val_file = pipeline.create_comprehensive_dataset()
        
        if train_file and val_file:
            # åˆ›å»ºé…ç½®æ–‡ä»¶
            config_file = create_llamafactory_config()
            
            print("\n" + "ğŸ‰" * 20)
            print("å¾®è°ƒæ•°æ®å‡†å¤‡å®Œæˆï¼")
            print("ğŸ‰" * 20)
            
            print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
            print(f"1. æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶è´¨é‡")
            print(f"2. æ ¹æ®éœ€è¦è°ƒæ•´LLaMA-Factoryé…ç½®")
            print(f"3. å‡†å¤‡GPUç¯å¢ƒè¿›è¡Œå¾®è°ƒè®­ç»ƒ")
            print(f"4. ç›‘æ§è®­ç»ƒè¿‡ç¨‹å’Œæ•ˆæœè¯„ä¼°")
            
        else:
            print("âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æºæ•°æ®æ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

